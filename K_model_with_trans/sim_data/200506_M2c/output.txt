OUTPUT

Filename: 200506_M2c
Directory: /pine/scr/s/k/sksuzuki/HOG_model/rozemarijn/K_nuc_trans/200506_M2c
Data file: 200506_M2c.txt

Generations: 1000
Individuals: 500
Mutation rate: 0.1
Crossover rate: 0.5




#!/usr/bin/env python

# Author: Kimiko Suzuki
# Date: 181013
# Notes: python35

# 200506 -> mean() -> sum for Pbs2 scoring and reversed nuc terms(bug fixs)

###################################################################
#IMPORT PACKAGES
###################################################################
import numpy as np
from scipy.integrate import odeint
# from scipy.optimize import curve_fit
from scipy.optimize import fsolve
from deap import base, creator, tools, algorithms
import os
import sys
import pickle
import time as timeski
import math
# from itertools import product
import pathlib
import pandas as pd
# import multiprocessing
# import sys
# import pathlib

###########################################################################
#LOAD EXPERIMENTAL DATA
###########################################################################

save_filename = '200506_M2c.txt'

# longleaf
base_folder = '/nas/longleaf/home/sksuzuki/rvdv/Prescaled_input/'
base_folder_2 = '/nas/longleaf/home/sksuzuki/MAPK_activation/'

#local testing
# base_folder = 'C:/Users/sksuzuki/Downloads/Rozemarijn/Prescaled_input/'
# base_folder_2 = 'C:/Users/sksuzuki/Desktop/killdevil/data/MAPK_activation/'

wt_phospho_folder = base_folder + 'WT_phospho'
t100a_folder = base_folder_2 + 'T100A'
pbs2_folder = base_folder_2 + 'Pbs2'
pbs2_t100a_folder = base_folder_2 + 'Pbs2_T100A'
wt_nuc_folder = base_folder + '90percent/WT_nuc'

# ramp_folder = '/nas/longleaf/home/sksuzuki/HOG_model/data/MAPK activation/ramp_1'
# ptpD_folder = '/nas/longleaf/home/sksuzuki/MAPK activation/ptpD'

# wt_folder = 'C:/Users/sksuzuki/Desktop/killdevil/data/MAPK_activation/WT'
# t100a_folder = 'C:/Users/sksuzuki/Desktop/killdevil/data/MAPK_activation/T100A'
# pbs2_folder = 'C:/Users/sksuzuki/Desktop/killdevil/data/MAPK_activation/Pbs2'
# pbs2_t100a_folder = 'C:/Users/sksuzuki/Desktop/killdevil/data/MAPK_activation/Pbs2_T100A'
# ramp_folder = 'C:/Users/sksuzuki/Desktop/killdevil/data/MAPK activation/ramp_1'
# ptpD_folder = 'C:/Users/sksuzuki/Desktop/killdevil/data/MAPK activation/ptpD'


def load_csv_data(folder):
    data = []
    doses = []
    for csv in pathlib.Path(folder).glob('*.csv'):
        f_data = pd.read_csv(csv)
        time = f_data.iloc[:,1].tolist()
        dose = f_data['Dose'][0]
        doses.append(dose)
        # f_data=f_data.set_index('Time')
        f_data = f_data.iloc[:,1:4].mean(axis=1)
        f_data = f_data.tolist()
        data.append(f_data)
    data = np.array(data)
    re_idx = sorted(range(len(doses)), key=lambda k: doses[k])
    data = data[re_idx]
    return time, list(data)

mapk_time, mapk_t100a_data = load_csv_data(t100a_folder)
mapk_time, map2k_wt_data = load_csv_data(pbs2_folder)
mapk_time, map2k_t100a_data = load_csv_data(pbs2_t100a_folder)
mapk_time_phospho, mapk_wt_data = load_csv_data(wt_phospho_folder)
nuc_time, wt_nuc_data = load_csv_data(wt_nuc_folder)

# mapk_pulse_time, mapk_pulse_data = load_csv_data(mapk_pulse)
# mapk_pulse_time, map2k_pulse_data = load_csv_data(map2k_pulse)
# mapk_time_ramp, ramp_data = load_csv_data(ramp_folder)
# mapk_time, mapk_ptpD_data = load_csv_data(ptpD_folder)
mapk_time_t100a_0 = [0, 30, 60, 90, 120, 150, 180, 240, 300]
# mapk_data_t100a_long = [mapk_t100a_data[0]]

###################################################################
#EA PARAMS
###################################################################

number_of_runs = 5
number_of_generations = 1000
number_of_individuals = 500
mutation_rate = 0.1
crossover_rate = 0.5
number_of_params = 19

#############################################################################
#Convert molecules to molar concentration
#############################################################################
def molarity_conversion(molecules):
    Na = 6.02214076*10**23
    cell_volume = 44                                 # volume of a yeast cell
    return molecules/(Na*cell_volume*10**-15)*1000000 # returns uM

# Protein concentrations (uM)
MAP3K_t = molarity_conversion(123+1207+1611) #ssk2+ssk22+ste11
MAP2K_t = molarity_conversion(4076)
MAPK_t = molarity_conversion(8225)
PTP_t = molarity_conversion(443+1324) # ptp2+ptp3

###################################################################
#MATRIX FOR VARIABLES TO INTERP AND EXPONENTIATE
###################################################################

def make_conversion_matrix(number_of_params):
    # want easily savable matrix to hold this info
    # interp boolean, interp range (min,max), power boolean, power number (y)
    arr_IandP = np.zeros((5,number_of_params))
    # Set all interp booleans to 1 - everything is going to be interpreted
    arr_IandP[0,:] = 1
    # Set all power booleans to 1 - everything is in the form of powers
    arr_IandP[3,:] = 1
    # Set all power numbers to 10 - everything has a base of 10
    arr_IandP[4,:] = 10
    # Set minimums and maximums for all parameters. Parameters are in the following order:
    minimums = [-4, -4, -4,
        -4, -4, -4, -4,
        -4, -4, -4, -4, -4,
        -4, -4, -4, -4,
        -4, -4, -4]

    maximums = [ 4, 4, 4,
        4, 4, 4, 4,
        4, 4, 4, 4, 4,
        4, 4, 4, 4,
        4, 4, 4]

    for i in range(len(minimums)):
        arr_IandP[1,i] = minimums[i] #interp_range_min
        arr_IandP[2,i] = maximums[i] #interp_range_max

    return arr_IandP


#############################################################################
#PARAMETERS
#############################################################################
# initial values
MAP3K = 0.05*MAP3K_t # estimated (so not 0)
MAP2K = 0.05975380333*MAP2K_t # from the biological data
MAPK = 0.00540042381*MAPK_t*.8  # from the biological data
MAPK_n = 0.00540042381*MAPK_t*.2 #20 percent?
gly = 0.00001 # placeholder (so not 0)
# PTP = molarity_conversion(443+1324) # ptp2+ptp3

# doses
hog1_doses = [150, 350, 550]
hog1_t100a_doses = [0, 150, 550]
# pbs2_doses = [150000, 550000]
# ptp_doses = [0, 150000, 550000]

inits = [MAP3K, MAP2K, MAPK, MAPK_n, gly]
total_protein = [MAP3K_t, MAP2K_t, MAPK_t, 1] #uM, except for gly (1) which is a placeholder for multiplying arrays together

#conversion matrix
arr_conversion_matrix = make_conversion_matrix(number_of_params)
#############################################################################
# MODEL
#############################################################################


def model(initials,t,total_protein,sig,params):
    MAP3K, MAP2K, MAPK, gly, MAPK_n = initials
    MAP3K_t, MAP2K_t, MAPK_t, _ = total_protein
    beta_3, alpha, kb, k1, k3, k5, s7, k2, k4, k6, d8, K_1, K_3, K_5, K_2, K_4, K_6, n1, n2 = params #17

    MAP3K_I = MAP3K_t-MAP3K
    MAP2K_I = MAP2K_t-MAP2K
    MAPK_I = MAPK_t-MAPK-MAPK_n

    dMAP3K = (((sig*k1 + kb)/(1+gly/beta_3))*MAP3K_I)/(K_1+MAP3K_I) - (k2*MAP3K/(K_2+MAP3K))
    dMAP2K = ((k3*MAP3K*MAP2K_I)/(K_3+MAP2K_I)) - (k4*MAP2K/(K_4+MAP2K))
    dMAPK = (((k5*MAP2K + MAPK*alpha))*MAPK_I)/(K_5+MAPK_I) - (k6*MAPK)/(K_6+MAPK)  + n2*MAPK_n - n1*MAPK
    dMAPK_n = n1*MAPK - n2*MAPK_n
    dgly = s7*MAPK - d8*gly

    return dMAP3K, dMAP2K, dMAPK, dMAPK_n, dgly

def run_ss(inits, total_protein, learned_params):
    ss = fsolve(model, inits, args=(0,total_protein, 0, learned_params))
    return ss

def simulate_wt_experiment(inits, total_protein, sig, learned_params, time):
    odes = odeint(model, inits, time, args=(total_protein, sig, learned_params))
    return odes


def simulate_t100a_experiment(inits, total_protein, sig, learned_params, time):
    beta_3, alpha, kb, k1, k3, k5, s7, k2, k4, k6, d8, K_1, K_3, K_5, K_2, K_4, K_6, n1, n2  = learned_params #16
    learned_params = beta_3, 0, kb, k1, k3, k5, 0, k2, k4, k6, d8, K_1, K_3, K_5, K_2, K_4, K_6, 0, n2
    #solve odes:
    odes = odeint(model, inits, time, args=(total_protein, sig, learned_params))
    return odes

#############################################################################
#EA FUNCTIONS
#############################################################################

def convert_individual(ea_individual, conversion_matrix, number_of_params):
    # copy and get len of individual
    arr_params_conv = np.zeros(number_of_params)#np.copy(arr_parameters)
    len_ind = len(ea_individual)

    # Interp:
    for idx in np.nonzero(conversion_matrix[0])[0]:
        ea_val = ea_individual[idx]
        r_min = conversion_matrix[1][idx]
        r_max = conversion_matrix[2][idx]
        arr_params_conv[idx] = np.interp(ea_val, (0,1), (r_min, r_max))

    # Exponentiate:
    for idx in np.nonzero(conversion_matrix[3])[0]:
        ea_val = arr_params_conv[idx]
        base_val = conversion_matrix[4][idx]
        arr_params_conv[idx] = np.power(base_val, ea_val)

    # arr_params_conv[-4:] = np.round(arr_params_conv[-4:],0)

    return arr_params_conv

def check_odes(odes):
    return np.any(np.array(odes) < 0)

def scorefxn1(inits, total_protein, learned_params):
    params = convert_individual(learned_params, arr_conversion_matrix, number_of_params)

    dt = 0.1
    steps = 601
    time = np.linspace(0,dt*steps,steps)
    time_long = np.linspace(0,dt*3001,steps)

    closest_idxs_phospho = [np.abs(time - t).argmin() for t in mapk_time_phospho]
    closest_idxs_other = [np.abs(time - t).argmin() for t in mapk_time]
    closest_idxs_t100a_0 = [np.abs(time_long - t).argmin() for t in mapk_time_t100a_0]
    closest_idxs_nuc = [np.abs(time-t).argmin() for t in nuc_time]

    # check if wt steady state exists, returns maximal MSE if not
    wt_ss_inits = run_ss(inits, total_protein, params)
    Hog1_ss = np.sum(wt_ss_inits[2:4])
    _t = np.concatenate([wt_ss_inits[:2],[Hog1_ss]],axis=0)
    check = total_protein[:-1] - _t
    if (check < 0).any():
        return ((9*5)*100)**2 #if sims were the oppsite of the data (not possible)

    mse_total = 0

    # WILDTYPE
    # Hog1
    for dose, data_phospho, data_nuc in zip(hog1_doses, mapk_wt_data, wt_nuc_data):
        odes = simulate_wt_experiment(wt_ss_inits, total_protein, dose, params, time)
        if check_odes(odes):
            return ((63+69+18*2+27)*100)**2
        mapk = (odes[:,2]+odes[:,3])/total_protein[2]*100 #calc as a percentage
        error_active = np.sum((data_phospho - mapk[closest_idxs_phospho])**2) #sum of squares to keep the same
        mse_total += error_active

        Hog1_nuc = odes[:,3]/total_protein[2]*100 #calc as a percentage
        error_nuc = np.sum((data_nuc - Hog1_nuc[closest_idxs_nuc])**2) #sum of squares to keep the same
        mse_total += error_nuc

        # Pbs2
        if dose == 150:
            map2k = odes[:,1]/total_protein[1]*100
            error_active = np.sum((map2k_wt_data[0] - map2k[closest_idxs_other])**2)
            mse_total += error_active
        elif dose == 550:
            map2k = odes[:,1]/total_protein[1]*100
            error_active = np.sum((map2k_wt_data[1] - map2k[closest_idxs_other])**2)
            mse_total += error_active

    # ANALOG SENSITIVE
    # Hog1
    for dose, data in zip(hog1_t100a_doses, mapk_t100a_data):
        if dose == 0:
            odes = simulate_t100a_experiment(wt_ss_inits, total_protein, dose, params, time_long)
            if check_odes(odes):
                return ((63+69+18*2+27)*100)**2
            mapk = (odes[:,2]+odes[:,3])/total_protein[2]*100 #calc as a percentage
            error_active = np.sum((data - mapk[closest_idxs_t100a_0])**2) #sum of squares to keep the same
            mse_total += error_active
        else:
            odes = simulate_t100a_experiment(wt_ss_inits, total_protein, dose, params, time)
            mapk = (odes[:,2]+odes[:,3])/total_protein[2]*100 #calc as a percentage
            error_active = np.sum((data - mapk[closest_idxs_other])**2) #sum of squares to keep the same
            mse_total += error_active

            # Pbs2
            if dose == 150:
                map2k = odes[:,1]/total_protein[1]*100
                error_active = np.sum((map2k_t100a_data[0] - map2k[closest_idxs_other])**2)
                mse_total += error_active
            elif dose == 550:
                map2k = odes[:,1]/total_protein[1]*100
                error_active = np.sum((map2k_t100a_data[1] - map2k[closest_idxs_other])**2)
                mse_total += error_active

    return mse_total


def scorefxn_helper(individual):
    # just a helper function that pulls all of scorefxn1 dependencies together
    # note the (), <--using single optimization in DEAP for now
    # scorefxn1 is taking care of the multiple optimizations for now
    return scorefxn1(inits, total_protein, individual),



###################################################################
#CHECK FOR / CREATE DIR FOR DATA
###################################################################
def strip_filename(fn):
    #input = full path filename
    #output = filename only
    #EX input = '/home/iammoresentient/phd_lab/data/data_posnegfb_3cellsum.pickled'
    #EX output = 'data_posnegfb_3cellsum'
    if '/' in fn:
        fn = fn.split('/')[-1]
    fn = fn.split('.')[0]
    return fn


def add_info(fn, gens, inds, mutationrate, crossoverrate):
    #input = filename only
    #output = date + filename + EA data
    # EX input = 'data_posnegfb_3cellsum'
    # EX output = '170327_data_posnegfb_3cellsum_#g#i#m#c'

    #get current date:
    cur_date = timeski.strftime('%y%m%d')
    # setup EA data:
    ea_data = str(gens) + 'g' + str(inds) + 'i' + str(int(mutationrate*100)) + 'm' + str(int(crossoverrate*100)) + 'c'
    #put it all together:
    #new_fn = cur_date + '_' + fn + '_' + ea_data
    new_fn = cur_date + '_' + os.path.basename(fn).split('.')[0].split('_')[-1] + '_' + ea_data
    return new_fn


stripped_name = strip_filename(save_filename)
informed_name = add_info(stripped_name, number_of_generations, number_of_individuals, mutation_rate, crossover_rate)
fn_to_use = informed_name
dir_to_use = os.getcwd() + '/' + stripped_name

#check if dir exists and make
if not os.path.isdir(dir_to_use):
    os.makedirs(dir_to_use)
    # print('Made: ' + dir_to_use)
    # and make README file:
    fn = dir_to_use + '/' + 'output.txt'
    file = open(fn, 'w')

    # write pertinent info at top
    file.write('OUTPUT\n\n')
    file.write('Filename: ' + stripped_name + '\n')
    file.write('Directory: ' + dir_to_use + '\n')
    file.write('Data file: ' + save_filename + '\n\n')
    file.write('Generations: ' + str(number_of_generations) + '\n')
    file.write('Individuals: ' + str(number_of_individuals) + '\n')
    file.write('Mutation rate: ' + str(mutation_rate) + '\n')
    file.write('Crossover rate: ' + str(crossover_rate) + '\n')
    file.write('\n\n\n\n')

    #write script to file
    #script_name = os.getcwd() + '/' + 'EA_1nf1pf.py'
    script_name = os.path.basename(__file__)#__file__)
    open_script = open(script_name, 'r')
    write_script = open_script.read()
    file.write(write_script)
    open_script.close()

    file.close()

###################################################################
#LOOP: EVOLUTIONARY ALGORITHM + SAVE DATA
##################################################################
# def run(): # DOGWOOD

for i in range(number_of_runs):
    ###################################################################
    #EVOLUTIONARY ALGORITHM
    ###################################################################
    #TYPE
    #Create minimizing fitness class w/ single objective:
    creator.create('FitnessMin', base.Fitness, weights=(-1.0,))
    #Create individual class:
    creator.create('Individual', list, fitness=creator.FitnessMin)

    #TOOLBOX
    toolbox = base.Toolbox()
    #Register function to create a number in the interval [1-100?]:
    #toolbox.register('init_params', )
    #Register function to use initRepeat to fill individual w/ n calls to rand_num:
    toolbox.register('individual', tools.initRepeat, creator.Individual,
                     np.random.random, n=number_of_params)
    #Register function to use initRepeat to fill population with individuals:
    toolbox.register('population', tools.initRepeat, list, toolbox.individual)

    #GENETIC OPERATORS:
    # Register evaluate fxn = evaluation function, individual to evaluate given later
    toolbox.register('evaluate', scorefxn_helper)
    # Register mate fxn = two points crossover function
    toolbox.register('mate', tools.cxTwoPoint)
    # Register mutate by swapping two points of the individual:
    toolbox.register('mutate', tools.mutPolynomialBounded,
                     eta=0.1, low=0.0, up=1.0, indpb=0.2)
    # Register select = size of tournament set to 3
    toolbox.register('select', tools.selTournament, tournsize=3)

    #EVOLUTION!
    pop = toolbox.population(n=number_of_individuals)
    hof = tools.HallOfFame(1)

    stats = tools.Statistics(key = lambda ind: [ind.fitness.values, ind])
    stats.register('all', np.copy)

    # using built in eaSimple algo
    pop, logbook = algorithms.eaSimple(pop, toolbox, cxpb=crossover_rate,
                                       mutpb=mutation_rate,
                                       ngen=number_of_generations,
                                       stats=stats, halloffame=hof,
                                       verbose=False)
    # print(f'Run number completed: {i}')

    ###################################################################
    #MAKE LISTS
    ###################################################################
    # Find best scores and individuals in population
    arr_best_score = []
    arr_best_ind = []
    for a in range(len(logbook)):
        scores = []
        for b in range(len(logbook[a]['all'])):
            scores.append(logbook[a]['all'][b][0][0])
        #print(a, np.nanmin(scores), np.nanargmin(scores))
        arr_best_score.append(np.nanmin(scores))
        #logbook is of type 'deap.creator.Individual' and must be loaded later
        #don't want to have to load it to view data everytime, thus numpy
        ind_np = np.asarray(logbook[a]['all'][np.nanargmin(scores)][1])
        ind_np_conv = convert_individual(ind_np, arr_conversion_matrix, number_of_params)
        arr_best_ind.append(ind_np_conv)
        #arr_best_ind.append(np.asarray(logbook[a]['all'][np.nanargmin(scores)][1]))


    # print('Best individual is:\n %s\nwith fitness: %s' %(arr_best_ind[-1],arr_best_score[-1]))

    ###################################################################
    #PICKLE
    ###################################################################
    arr_to_pickle = [arr_best_score, arr_best_ind]

    def get_filename(val):
        filename_base = dir_to_use + '/' + stripped_name + '_'
        if val < 10:
            toret = '000' + str(val)
        elif 10 <= val < 100:
            toret = '00' + str(val)
        elif 100 <= val < 1000:
            toret = '0' + str(val)
        else:
            toret = str(val)
        return filename_base + toret + '.pickled'

    counter = 0
    filename = get_filename(counter)
    while os.path.isfile(filename) == True:
        counter += 1
        filename = get_filename(counter)

    pickle.dump(arr_to_pickle, open(filename,'wb'))
#     print('Dumped data to file here: ', filename)

# FOR DOGWOOD
# def throw_away_function(_):
#     return run()
#
# def main():
#     pool=multiprocessing.Pool(processes=number_of_runs)
#     pool.map(throw_away_function, range(number_of_runs))
#
# if __name__ == '__main__':
#     main()
